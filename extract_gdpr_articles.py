#!/usr/bin/env python3
"""
Extract GDPR Article Titles from PDF

This script automatically extracts article titles from the GDPR PDF document
and updates the articles.yaml knowledge base. This eliminates the need for
manual entry of article titles.
"""

import re
from pathlib import Path

from src.poliverai.ingestion.readers.pdf_reader import read_pdf_text

# Constants
MAX_TITLE_LENGTH = 200


def extract_articles_from_gdpr_pdf(pdf_path: str) -> dict:
    """Extract article titles from GDPR PDF."""
    print(f"üìñ Reading GDPR PDF from: {pdf_path}")
    text = read_pdf_text(pdf_path)

    # Pattern to find articles with titles
    article_pattern = r"Article (\d+(?:\(\d+\))?(?:\([a-z]\))?)\s*\n([^\n]+)"
    matches = re.findall(article_pattern, text, re.MULTILINE | re.IGNORECASE)

    articles = {}
    base_articles = {}  # Store base article titles for subsections

    for article_num, title in matches:
        # Clean up the article number and title
        article_key = f"Article {article_num}"
        clean_title = title.strip()

        # Skip if title looks like content rather than a title
        if len(clean_title) > MAX_TITLE_LENGTH or clean_title.lower().startswith("where "):
            continue

        articles[article_key] = clean_title

        # Store base article title for creating subsection titles
        base_num = article_num.split("(")[0]
        if "(" not in article_num:  # This is a main article
            base_articles[base_num] = clean_title

    # Add common subsections based on main articles
    common_subsections = {
        "1": [(1, "Subject-matter and objectives")],
        "2": [(1, "Material scope")],
        "3": [(1, "Territorial scope"), (2, "Territorial scope")],
        "5": [
            (1, "Principles relating to processing of personal data"),
            (2, "Principles relating to processing of personal data"),
        ],
        "6": [(1, "Lawfulness of processing")],
        "8": [
            (
                1,
                "Conditions applicable to child's consent in relation to "
                "information society services",
            )
        ],
        "89": [
            (
                1,
                "Safeguards and derogations relating to processing for archiving purposes "
                "in the public interest, scientific or historical research purposes or "
                "statistical purposes",
            )
        ],
    }

    # Add subsection articles
    for base_num, subsections in common_subsections.items():
        if base_num in base_articles:
            base_title = base_articles[base_num]
            for sub_num, sub_title in subsections:
                subsection_key = f"Article {base_num}({sub_num})"
                if subsection_key not in articles:
                    articles[subsection_key] = sub_title or base_title

    print(f"‚úÖ Extracted {len(articles)} articles from PDF (including subsections)")
    return articles


def generate_articles_yaml(articles: dict, output_path: str):
    """Generate a comprehensive articles.yaml file."""
    yaml_content = ["# GDPR Articles automatically extracted from official PDF"]
    yaml_content.append("# This file is generated by extract_gdpr_articles.py")
    yaml_content.append("")

    for article_key, title in sorted(articles.items(), key=lambda x: _sort_article_key(x[0])):
        # Create YAML entry
        yaml_entry = {
            "article": article_key,
            "title": title,
            "summary": f"Official GDPR provision: {title}",
            "tags": _generate_tags(title),
        }

        yaml_content.append(f'- article: "{article_key}"')
        yaml_content.append(f'  title: "{title}"')
        yaml_content.append(f'  summary: "{yaml_entry["summary"]}"')
        yaml_content.append(f"  tags: {yaml_entry['tags']}")

    # Write to file
    with open(output_path, "w", encoding="utf-8") as f:
        f.write("\n".join(yaml_content))

    print(f"üìù Generated {output_path} with {len(articles)} articles")


def _sort_article_key(article_key: str) -> tuple:
    """Sort article keys numerically."""
    # Extract numbers for proper sorting (Article 1, Article 2, ..., Article 99)

    match = re.match(r"Article (\d+)(?:\((\d+)\))?(?:\(([a-z])\))?", article_key)
    if match:
        main_num = int(match.group(1))
        sub_num = int(match.group(2)) if match.group(2) else 0
        sub_letter = ord(match.group(3)) - ord("a") if match.group(3) else 0
        return (main_num, sub_num, sub_letter)
    return (999, 999, 999)  # Put unmatched at end


def _generate_tags(title: str) -> list:
    """Generate tags based on article title."""
    title_lower = title.lower()
    tags = []

    # Common GDPR concepts
    tag_mapping = {
        "processing": ["processing"],
        "consent": ["consent"],
        "data subject": ["data subject rights"],
        "right": ["data subject rights"],
        "controller": ["controller"],
        "processor": ["processor"],
        "transfer": ["international transfers"],
        "breach": ["data breach"],
        "security": ["security"],
        "supervisory": ["supervisory authority"],
        "fine": ["penalties"],
        "principle": ["principles"],
        "lawful": ["lawful basis"],
        "scope": ["scope"],
        "definition": ["definitions"],
        "child": ["children"],
        "special": ["special categories"],
        "impact": ["DPIA"],
        "officer": ["DPO"],
        "record": ["records"],
    }

    for keyword, tag_list in tag_mapping.items():
        if keyword in title_lower:
            tags.extend(tag_list)

    # Remove duplicates and return
    return list(set(tags)) if tags else ["gdpr"]


def main():
    """Main extraction process."""
    print("üéØ GDPR Article Title Extraction")
    print("=" * 50)

    # Paths
    gdpr_pdf = "gdpr.pdf"
    articles_yaml = "src/poliverai/knowledge/gdpr/articles.yaml"

    # Check if PDF exists
    if not Path(gdpr_pdf).exists():
        print(f"‚ùå GDPR PDF not found: {gdpr_pdf}")
        print("Please ensure gdpr.pdf is in the project root directory.")
        return

    # Extract articles
    articles = extract_articles_from_gdpr_pdf(gdpr_pdf)

    if not articles:
        print("‚ùå No articles extracted from PDF")
        return

    # Show sample
    print("\nüìã Sample extracted articles:")
    for _i, (article, title) in enumerate(list(articles.items())[:10]):
        print(f"  {article}: {title}")
    print(f"  ... and {len(articles) - 10} more")

    # Generate YAML
    generate_articles_yaml(articles, articles_yaml)

    print(f"\n‚úÖ Success! Updated {articles_yaml}")
    print("üîÑ Restart the server to load the new article titles")
    print("üéâ Query sources will now show full article titles!")

    # Show some examples of what will be improved
    print("\nüí° Examples of improvements:")
    sample_articles = list(articles.items())[:5]
    for article, title in sample_articles:
        print(f"  BEFORE: {article}")
        print(f"  AFTER:  {article} {title}")
        print()


if __name__ == "__main__":
    main()
